{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 值迭代算法\n",
    "基于MDP假设的强化学习中，我们会用一个状态-动作表(Q表)来记录在某个状态下执行某个动作的预期奖赏。如果MDP的环境已知，即我们知道了states的总数和每个state对应的可能的actions，就可以用值迭代算法通过N次迭代计算出每个状态对应的状态值函数V(x)。迭代公式是\n",
    "$$ V'(x) = max_{a \\in A} \\sum_{x' \\in X} P_{x \\rightarrow x'}^{a}(R_{x \\rightarrow x'}^{a}+\\gamma V(x')) $$\n",
    "即我们每次迭代对所有状态按照上式进行一次更新，并且在每个状态的前瞻动作-状态对中，贪心地选择最好的reward值来更新当前的V值。最终我们会得到一个收敛的V函数，在决策时，只需要在每一步的x时，选择让下一步的V值$V(x')$最大的动作$a(x\\rightarrow x')$即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-learning\n",
    "但是事实往往并不如所愿，想要完全获悉一个MDP过程的全部state信息和action信息在正常任务中一般是不可行的。事实上我们常常发现，一个MDP中的状态数会随着独立的unit数目指数级别增长，即使是斗地主这种只有50几张牌，3个玩家的游戏，所对应的全部状态也几乎无法计算。而状态对应的动作就更为具有挑战性了，毕竟状态数已经很多，如果每种状态对应的动作很多，很多时候我们只有在获知状态后才能得知下一步的动作。  \n",
    "为此我们有一种不需要得知MDP的环境信息也能进行学习的算法，Q-learning。因为现在我们不能得到状态数，也就无法建立V表，但我们可以建立一种基于状态-动作对的估值函数Q(x,a)，也就是Q表。为了代替上面的算法，这种算法允许agent通过在环境中不断采样来更新Q值，并在多次更新求平均的过程中达到收敛。  \n",
    "$$ Q(x,a) = (1-\\alpha)Q(x,a)+\\alpha (R(x',a') + \\gamma Q(x',a')) $$\n",
    "其中alpha是学习率，表示Q值的更新速度；gamma是奖赏discount。其中x'的选取是依赖当前学习到的策略Q的，有时我们也会为了探索而附加一些噪音。这种学习方法允许在线学习，而且可以帮助我们避开很多无效的状态。这种让agent亲自在环境中探索并学习的方式也更易于应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学习井字棋\n",
    "当我们要把上面的算法应用到实际场景中也会面临一些难题。用一个最简单的井字棋对弈问题为例，这个问题的状态空间总数是$3^9=19683$，似乎并不是太多。但是其中有着相当多的无效状态，因为我们的对弈是每个玩家轮流下子，而且一旦一方胜利游戏就会结束，再并且每一步的action都是不同的，都需要独立计算。这就让值迭代算法变得不可行。  \n",
    "而如果我们要用Q-learning来学习，又有其他问题。这个问题中我们让agent在环境中采样，就只能让两个agent互相下棋，而agent每下一步所获得的reward都是无法获知的。我们需要自己设计其他的评估策略来从游戏的胜负平中得到奖赏信息。  \n",
    "进一步分析问题，井字棋游戏是双方平等的游戏。每次一方落子后换边下棋，只需要把黑白子反转，就能用完全相同的评估策略来评估局势。评估局势的过程和action的关系并不大，在当前的状态x采取某状态变换到下一个状态x'，局势的好坏只取决于x'.因此我们的学习目标是一个值函数V(x)。  \n",
    "奖赏的设计。我们在游戏结束后会判一方胜利或两方平局，很显然胜利的一方的所有决策都对这个胜利有帮助，我们会为所有操作奖赏1，并用Q-learning为所有状态提供衰减过后的奖赏。同理，失败的一方会受到-1的惩罚奖励。如果两者平局，我们的经验告诉我们，后手方是井字棋游戏中明显处于劣势的一方，我们也会给先手方一个小的惩罚-0.1，而后手方则会得到小的奖励0.1。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T04:44:01.861582Z",
     "start_time": "2020-04-28T04:44:01.842562Z"
    }
   },
   "outputs": [],
   "source": [
    "# 首先设计井字棋游戏的基本逻辑和V表\n",
    "\n",
    "values = {}\n",
    "#我们的棋盘会用一个长度9的字符串表示，对己方、对方和空格分别用O X _代指\n",
    "\n",
    "def exchange(board):\n",
    "    '''\n",
    "    输入:board,string,棋盘字符串\n",
    "    输出:交换OX后的棋盘字符串\n",
    "    '''\n",
    "    board = board.replace('O','0')\n",
    "    board = board.replace('X','x')\n",
    "    board = board.replace('0','X')\n",
    "    board = board.replace('x','O')\n",
    "    return board\n",
    "\n",
    "def EnumAllStates(size = 9):\n",
    "    '''\n",
    "    输出:所有可能的state字符串\n",
    "    用于初始化values表\n",
    "    '''\n",
    "    prefix = [\"O\",\"X\",\"_\"]\n",
    "    if size==1:\n",
    "        return prefix\n",
    "    postfix = EnumAllStates(size-1)\n",
    "    ret = []\n",
    "    for pre in prefix:\n",
    "        for post in postfix:\n",
    "            ret.append(pre+post)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T04:44:02.406478Z",
     "start_time": "2020-04-28T04:44:02.396454Z"
    }
   },
   "outputs": [],
   "source": [
    "states = EnumAllStates()\n",
    "for state in states:\n",
    "    values[state] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T04:44:03.055764Z",
     "start_time": "2020-04-28T04:44:02.890326Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def WinCheck(board):\n",
    "    '''\n",
    "    输入:board,string,棋盘字符串\n",
    "    输出:string,胜负判断\n",
    "    '''\n",
    "    board = list(board)\n",
    "    board = np.array(board).reshape(3,3)\n",
    "    if (np.diag(board)=='O').all():\n",
    "        return \"win\"\n",
    "    elif (np.diag(np.flipud(board))=='O').all():\n",
    "        return \"win\"\n",
    "    elif (board[0]=='O').all() or (board[1]=='O').all() or (board[2]=='O').all():\n",
    "        return \"win\"\n",
    "    elif (board[:,0]=='O').all() or (board[:,1]=='O').all() or (board[:,2]=='O').all():\n",
    "        return \"win\"\n",
    "    elif (np.diag(board)=='X').all():\n",
    "        return \"lose\"\n",
    "    elif (np.diag(np.flipud(board))=='X').all():\n",
    "        return \"lose\"\n",
    "    elif (board[0]=='X').all() or (board[1]=='X').all() or (board[2]=='X').all():\n",
    "        return \"lose\"\n",
    "    elif (board[:,0]=='X').all() or (board[:,1]=='X').all() or (board[:,2]=='X').all():\n",
    "        return \"lose\"\n",
    "    elif '_' not in board.squeeze():\n",
    "        return \"draw\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "def successors(board):\n",
    "    '''\n",
    "    得到board的所有落子选项对应的状态\n",
    "    并返回含有所有后续状态的列表\n",
    "    '''\n",
    "    ret = []\n",
    "    for i in range(9):\n",
    "        if board[i]=='_':\n",
    "            ret.append(board[:i]+'O'+board[i+1:])\n",
    "    return ret\n",
    "\n",
    "def policy(board, values, noise = 0):\n",
    "    '''\n",
    "    根据values做出决策，noise可以得到一些\n",
    "    非最优选择\n",
    "    '''\n",
    "    states = successors(board)\n",
    "    if random.random()<noise:\n",
    "        return random.choice(states)\n",
    "    state = max(states,key = lambda key:values[key])\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T04:44:03.505404Z",
     "start_time": "2020-04-28T04:44:03.407111Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(values, lr = 0.2, noise = 0.1, iters = 100000,\n",
    "         discount = 0.8, win_reward = 1, draw_reward = 0.1):\n",
    "    '''\n",
    "    通过对抗方式训练values表\n",
    "    '''\n",
    "    Awin = 0\n",
    "    Bwin = 0\n",
    "    draw = 0\n",
    "    \n",
    "    \n",
    "    for t in range(iters):\n",
    "        pathA = []  # 先手的状态路径\n",
    "        pathB = []  # 后手的状态路径\n",
    "        player = -1\n",
    "        path_dict = {-1:pathA,1:pathB}\n",
    "        board = \"_________\"\n",
    "        winner = 0  #0表示平局，1为B获胜，-1为A获胜\n",
    "        while(1):\n",
    "            # 得到下一步的落子策略\n",
    "            state = policy(board, values, noise = noise)\n",
    "            path_dict[player].append(state)\n",
    "            # 胜负检测\n",
    "            info = WinCheck(state)\n",
    "            if info==\"win\":\n",
    "                winner = player\n",
    "            elif info==\"lose\":\n",
    "                winner = -player\n",
    "            elif info==\"draw\":\n",
    "                winner = 0\n",
    "            if info!=\"unknown\":\n",
    "                break\n",
    "            board = exchange(state) #交换O与X\n",
    "            player = -player  #交换玩家\n",
    "        # 更新values\n",
    "        if winner==-1:\n",
    "        # 奖励A，惩罚B\n",
    "            reward = win_reward\n",
    "            Awin += 1\n",
    "        elif winner==1:\n",
    "            # 奖励B，惩罚A\n",
    "            reward = -win_reward\n",
    "            Bwin += 1\n",
    "        elif winner==0:\n",
    "            # 轻微惩罚A，轻微奖励B\n",
    "            reward = -draw_reward\n",
    "            draw += 1\n",
    "        values[pathA[-1]] = (1-lr)*values[pathA[-1]]+lr*reward\n",
    "        for i in range(len(pathA)-2,-1,-1):\n",
    "            values[pathA[i]] = (1-lr)*values[pathA[i]]+\\\n",
    "            lr*(reward+values[pathA[i+1]]*discount)\n",
    "        values[pathB[-1]] = (1-lr)*values[pathB[-1]]+lr*(-reward)\n",
    "        for i in range(len(pathB)-2,-1,-1):\n",
    "            values[pathB[i]] = (1-lr)*values[pathB[i]]+\\\n",
    "            lr*((-reward)+values[pathB[i+1]]*discount)\n",
    "        if (t+1)%5000==0:\n",
    "            print(\"Iteration: %d\"%(t+1))\n",
    "            print(\"A win times: %d\"%(Awin))\n",
    "            print(\"B win times: %d\"%(Bwin))\n",
    "            print(\"Draw times: %d\"%(draw))\n",
    "            print(\"**---------------------**\")\n",
    "        \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T04:45:03.707064Z",
     "start_time": "2020-04-28T04:44:04.039365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5000\n",
      "A win times: 1802\n",
      "B win times: 912\n",
      "Draw times: 2286\n",
      "**---------------------**\n",
      "Iteration: 10000\n",
      "A win times: 2899\n",
      "B win times: 1403\n",
      "Draw times: 5698\n",
      "**---------------------**\n",
      "Iteration: 15000\n",
      "A win times: 4006\n",
      "B win times: 1988\n",
      "Draw times: 9006\n",
      "**---------------------**\n",
      "Iteration: 20000\n",
      "A win times: 5041\n",
      "B win times: 2472\n",
      "Draw times: 12487\n",
      "**---------------------**\n",
      "Iteration: 25000\n",
      "A win times: 6077\n",
      "B win times: 2910\n",
      "Draw times: 16013\n",
      "**---------------------**\n",
      "Iteration: 30000\n",
      "A win times: 7149\n",
      "B win times: 3360\n",
      "Draw times: 19491\n",
      "**---------------------**\n",
      "Iteration: 35000\n",
      "A win times: 8202\n",
      "B win times: 3758\n",
      "Draw times: 23040\n",
      "**---------------------**\n",
      "Iteration: 40000\n",
      "A win times: 9219\n",
      "B win times: 4182\n",
      "Draw times: 26599\n",
      "**---------------------**\n",
      "Iteration: 45000\n",
      "A win times: 10213\n",
      "B win times: 4587\n",
      "Draw times: 30200\n",
      "**---------------------**\n",
      "Iteration: 50000\n",
      "A win times: 11279\n",
      "B win times: 4955\n",
      "Draw times: 33766\n",
      "**---------------------**\n",
      "Iteration: 55000\n",
      "A win times: 12254\n",
      "B win times: 5422\n",
      "Draw times: 37324\n",
      "**---------------------**\n",
      "Iteration: 60000\n",
      "A win times: 13252\n",
      "B win times: 5831\n",
      "Draw times: 40917\n",
      "**---------------------**\n",
      "Iteration: 65000\n",
      "A win times: 14282\n",
      "B win times: 6275\n",
      "Draw times: 44443\n",
      "**---------------------**\n",
      "Iteration: 70000\n",
      "A win times: 15285\n",
      "B win times: 6693\n",
      "Draw times: 48022\n",
      "**---------------------**\n",
      "Iteration: 75000\n",
      "A win times: 16308\n",
      "B win times: 7167\n",
      "Draw times: 51525\n",
      "**---------------------**\n",
      "Iteration: 80000\n",
      "A win times: 17343\n",
      "B win times: 7597\n",
      "Draw times: 55060\n",
      "**---------------------**\n",
      "Iteration: 85000\n",
      "A win times: 18407\n",
      "B win times: 8023\n",
      "Draw times: 58570\n",
      "**---------------------**\n",
      "Iteration: 90000\n",
      "A win times: 19473\n",
      "B win times: 8390\n",
      "Draw times: 62137\n",
      "**---------------------**\n",
      "Iteration: 95000\n",
      "A win times: 20536\n",
      "B win times: 8850\n",
      "Draw times: 65614\n",
      "**---------------------**\n",
      "Iteration: 100000\n",
      "A win times: 21632\n",
      "B win times: 9270\n",
      "Draw times: 69098\n",
      "**---------------------**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(values)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T04:45:09.888209Z",
     "start_time": "2020-04-28T04:45:09.844106Z"
    }
   },
   "outputs": [],
   "source": [
    "# 我们可以用学习完毕的values来建立一个下棋bot\n",
    "# 让它和人类对弈来检验算法正确性\n",
    "\n",
    "def PrintBoard(board):\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            print(board[i*3+j],end = ' ')\n",
    "        print()\n",
    "\n",
    "\n",
    "def agent(values):\n",
    "    player = input(\"您想要先手还是后手？(enter o or d)\")\n",
    "    player = -1 if player=='o' else 1\n",
    "    board = \"_________\"\n",
    "    PrintBoard(board)\n",
    "    while(1):\n",
    "        if player == -1:\n",
    "            #人类下棋\n",
    "            n = input(\"请输入落子位置(1~9)\")\n",
    "            n = int(n)-1\n",
    "            board = board[:n]+'O'+board[n+1:]\n",
    "            PrintBoard(board)\n",
    "            \n",
    "        else:\n",
    "            # 机器下棋\n",
    "            print(\"Agent正在思考...\")\n",
    "            board = policy(board, values)\n",
    "            board = exchange(board)\n",
    "            PrintBoard(board)\n",
    "            board = exchange(board)\n",
    "        \n",
    "        # 胜负检测\n",
    "        info = WinCheck(board)\n",
    "        if info!=\"unknown\":\n",
    "            break\n",
    "        \n",
    "        player = -player\n",
    "        board = exchange(board)\n",
    "        \n",
    "    print(\"Game over!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T04:46:40.170777Z",
     "start_time": "2020-04-28T04:45:59.347770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您想要先手还是后手？(enter o or d)o\n",
      "_ _ _ \n",
      "_ _ _ \n",
      "_ _ _ \n",
      "请输入落子位置(1~9)4\n",
      "_ _ _ \n",
      "O _ _ \n",
      "_ _ _ \n",
      "Agent正在思考...\n",
      "X _ _ \n",
      "O _ _ \n",
      "_ _ _ \n",
      "请输入落子位置(1~9)5\n",
      "X _ _ \n",
      "O O _ \n",
      "_ _ _ \n",
      "Agent正在思考...\n",
      "X _ _ \n",
      "O O X \n",
      "_ _ _ \n",
      "请输入落子位置(1~9)7\n",
      "X _ _ \n",
      "O O X \n",
      "O _ _ \n",
      "Agent正在思考...\n",
      "X _ X \n",
      "O O X \n",
      "O _ _ \n",
      "请输入落子位置(1~9)2\n",
      "X O X \n",
      "O O X \n",
      "O _ _ \n",
      "Agent正在思考...\n",
      "X O X \n",
      "O O X \n",
      "O _ X \n",
      "Game over!\n"
     ]
    }
   ],
   "source": [
    "agent(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
